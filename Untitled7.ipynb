{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xKVnldHRJkO",
        "outputId": "91728f09-b35a-4d41-bf90-d9cd7b512351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#for reading in data properly\n",
        "import ast\n",
        "import json\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, LSTM, SimpleRNN, Dense, Dropout, Flatten, Bidirectional\n",
        "from keras.layers import Input, concatenate, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Sequential, Model\n",
        "from keras.regularizers import l2\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('output.csv', index_col=0)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "GSybl8evRUqe",
        "outputId": "be1c3af4-c265-42f8-e341-7d3fbb708aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    email                                               text  4.1  4.2  4.3  \\\n",
              "0  174119  message cut conclusion continue need address k...    0    0    0   \n",
              "1  125766  today news weekend follow order year later ene...    0    0    0   \n",
              "2   52167  vince ive hearing rumor decide endorse nodal p...    0    0    0   \n",
              "3  221197  jim able provide dan meeting would appreciate ...    0    0    0   \n",
              "4  150202  stan understand completely best achieve desire...    0    0    0   \n",
              "\n",
              "   4.4  4.5  4.6  4.7  4.8  ...  3.4  3.5  3.6  3.7  3.8  3.9  3.10  3.11  \\\n",
              "0    0    0    0    0    0  ...    0    0    0    0    0    0     0     0   \n",
              "1    0    0    0    0    0  ...    1    0    0    0    0    0     0     0   \n",
              "2    0    0    0    0    0  ...    0    0    0    0    0    0     0     0   \n",
              "3    1    0    0    0    0  ...    0    0    0    0    1    0     0     0   \n",
              "4    0    0    0    0    0  ...    0    0    0    0    0    0     0     0   \n",
              "\n",
              "   3.12  3.13  \n",
              "0     0     0  \n",
              "1     0     0  \n",
              "2     0     0  \n",
              "3     0     0  \n",
              "4     0     0  \n",
              "\n",
              "[5 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d712b9e-debb-4cd9-ba1b-76b5f9681361\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email</th>\n",
              "      <th>text</th>\n",
              "      <th>4.1</th>\n",
              "      <th>4.2</th>\n",
              "      <th>4.3</th>\n",
              "      <th>4.4</th>\n",
              "      <th>4.5</th>\n",
              "      <th>4.6</th>\n",
              "      <th>4.7</th>\n",
              "      <th>4.8</th>\n",
              "      <th>...</th>\n",
              "      <th>3.4</th>\n",
              "      <th>3.5</th>\n",
              "      <th>3.6</th>\n",
              "      <th>3.7</th>\n",
              "      <th>3.8</th>\n",
              "      <th>3.9</th>\n",
              "      <th>3.10</th>\n",
              "      <th>3.11</th>\n",
              "      <th>3.12</th>\n",
              "      <th>3.13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174119</td>\n",
              "      <td>message cut conclusion continue need address k...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125766</td>\n",
              "      <td>today news weekend follow order year later ene...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>52167</td>\n",
              "      <td>vince ive hearing rumor decide endorse nodal p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>221197</td>\n",
              "      <td>jim able provide dan meeting would appreciate ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150202</td>\n",
              "      <td>stan understand completely best achieve desire...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d712b9e-debb-4cd9-ba1b-76b5f9681361')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d712b9e-debb-4cd9-ba1b-76b5f9681361 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d712b9e-debb-4cd9-ba1b-76b5f9681361');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eragSWqPRMKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train['text'].values.tolist()\n",
        "y = train[['4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '4.10',\n",
        "       '4.11', '4.12', '4.13', '4.14', '4.15', '4.16', '4.17', '4.18', '4.19',\n",
        "       '1.1', '1.2', '1.3', '1.4', '1.5', '1.6', '1.7', '1.8', '2.1', '2.2',\n",
        "       '2.3', '2.4', '2.5', '2.6', '2.7', '2.8', '2.9', '2.10', '2.11', '2.12',\n",
        "       '2.13', '3.1', '3.2', '3.3', '3.4', '3.5', '3.6', '3.7', '3.8', '3.9',\n",
        "       '3.10', '3.11', '3.12', '3.13']]\n",
        "x_test = test['text'].values.tolist()\n",
        "y_test = test[['4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '4.10',\n",
        "       '4.11', '4.12', '4.13', '4.14', '4.15', '4.16', '4.17', '4.18', '4.19',\n",
        "       '1.1', '1.2', '1.3', '1.4', '1.5', '1.6', '1.7', '1.8', '2.1', '2.2',\n",
        "       '2.3', '2.4', '2.5', '2.6', '2.7', '2.8', '2.9', '2.10', '2.11', '2.12',\n",
        "       '2.13', '3.1', '3.2', '3.3', '3.4', '3.5', '3.6', '3.7', '3.8', '3.9',\n",
        "       '3.10', '3.11', '3.12', '3.13']]"
      ],
      "metadata": {
        "id": "mnTQTk_zSEh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = np.array(y)\n",
        "\n",
        "\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "-eP4EdDBSb1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4b5vykQSxEs",
        "outputId": "e9378270-ed7c-40fa-eddf-8d981ca556cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok = [word_tokenize(ov) for ov in x]\n"
      ],
      "metadata": {
        "id": "1aVcIKwtSgGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vec_len = 32\n",
        "w2v = Word2Vec(tok, min_count = 2, size=word_vec_len)"
      ],
      "metadata": {
        "id": "a6TxEr10SvAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words_kept = 100000 #using 100000 most popular words, use throughout\n",
        "\n",
        "tokenizer = Tokenizer(num_words_kept)\n",
        "tokenizer.fit_on_texts(x)\n",
        "sequences = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "max_seq_len = 150 #larger than averaage but not too large\n",
        "\n",
        "#get actual train features to feed into neural nets for training\n",
        "x_train_seq = pad_sequences(sequences, maxlen=max_seq_len)"
      ],
      "metadata": {
        "id": "A03E2bazS1ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "#get actual test features to feed into neural nets for testing\n",
        "x_test_seq = pad_sequences(test_sequences, maxlen=max_seq_len)"
      ],
      "metadata": {
        "id": "-IYm2QtvS6mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "for w in w2v.wv.vocab.keys():\n",
        "    embeddings_index[w] = w2v.wv[w]\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((num_words_kept, word_vec_len))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= num_words_kept:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "_mrz9YZYS-4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_per_label_metrics(real_labels_matrix, predictions_labels_matrix):\n",
        "    for genre in genre_dict.keys():\n",
        "        index = genre_dict[genre]\n",
        "        real_labels_vect = real_labels_matrix[:, index]\n",
        "        prediction_vect = predictions_labels_matrix[:,index]\n",
        "        print(\"Accuruacy for \" + genre + \": \" + str(accuracy_score(real_labels_vect, prediction_vect)))\n",
        "        print(\"Precision for \" + genre + \": \" + str(precision_score(real_labels_vect, prediction_vect)))\n",
        "        print(\"Recall for \" + genre + \": \" + str(recall_score(real_labels_vect, prediction_vect)))\n",
        "        print()"
      ],
      "metadata": {
        "id": "GDKLngZyTDCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_accuracy(real_labels_matrix, predictions_labels_matrix):\n",
        "    #binary so set intersection is and operator\n",
        "    intersection = real_labels_matrix & predictions_labels_matrix\n",
        "    #set union for binary is same as or operator\n",
        "    union = real_labels_matrix | predictions_labels_matrix\n",
        "    #sum(array.T) gets number of 1s in row\n",
        "    row_wise_accuracy = sum(intersection.T) / sum(union.T)\n",
        "    return sum(row_wise_accuracy) / real_labels_matrix.shape[0]\n",
        "\n",
        "#size of intersection of predicted and actual labels divided by size of predicted set for each datapoint tested on\n",
        "#sum those and divide by number of datapoints\n",
        "#if no predicted labels, don't count that row towards the precision as that would be undefined\n",
        "def multi_label_precision(real_labels_matrix, predictions_labels_matrix):\n",
        "    #binary so set intersection is and operator\n",
        "    intersection = real_labels_matrix & predictions_labels_matrix\n",
        "    precision_sum = 0\n",
        "    num_rows = 0\n",
        "    for row in range(intersection.shape[0]):\n",
        "        if sum(predictions_labels_matrix[row]) > 0: #if there is at least one prediction for this row\n",
        "            num_rows += 1\n",
        "            precision_sum += sum(intersection[row]) / sum(predictions_labels_matrix[row])\n",
        "    if num_rows == 0:\n",
        "        return 0#no labels predicted at all will give us 0 precision as precision makes no sense here\n",
        "    return precision_sum / num_rows\n",
        "\n",
        "#size of intersection of predicted and actual labels divided by size of real label set for each datapoint tested on\n",
        "#sum those and divide by number of datapoints\n",
        "#all datapoints should have at least 1 real label in this data set\n",
        "#vectorized for speed\n",
        "def multi_label_recall(real_labels_matrix, predictions_labels_matrix):\n",
        "    #binary so set intersection is and operator\n",
        "    intersection = real_labels_matrix & predictions_labels_matrix\n",
        "    #set union for binary is same as or operator\n",
        "    #sum(array.T) gets number of 1s in row\n",
        "    row_wise_recall = sum(intersection.T) / sum(real_labels_matrix.T)\n",
        "    return sum(row_wise_recall) / real_labels_matrix.shape[0]\n",
        "\n",
        "#lower is better. Percent incorrectly chosen labels counting assignment and non-assignment equally\n",
        "def hamming_loss(real_labels_matrix, predictions_labels_matrix):\n",
        "    return (np.logical_xor(real_labels_matrix, predictions_labels_matrix)).sum()/(real_labels_matrix.shape[0] * real_labels_matrix.shape[1])\n",
        "\n",
        "\n",
        "#K is what we imported keras backend as\n",
        "\n",
        "#metric for keras for early stopping\n",
        "#takes in raw labels from kerass (not yet converted to 0 and 1s)\n",
        "#NOT the same as accuracy, this is total labels correctly identified divided by union of total labels\n",
        "#this weights rows with more labels higher, where accruacy does not, but this is still a good metric for early stopping\n",
        "def raw_multi_label_accuracy(y_true, y_pred):\n",
        "    positives = K.greater_equal(y_pred, 0.5)\n",
        "    positives = K.cast(positives, K.floatx())\n",
        "    new_y_pred = positives #+ ((1-positives)*y_pred)\n",
        "    intersection = y_true * new_y_pred\n",
        "    union = 1 -((1-y_true)*(1-new_y_pred))\n",
        "    accuracy = K.sum(intersection) / K.sum(union)\n",
        "    return accuracy\n",
        "    "
      ],
      "metadata": {
        "id": "iJuU1zu8TJZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_metrics(actual_labels, predictions):\n",
        "    print('Getting evaluation metrics for each label:')\n",
        "    get_per_label_metrics(actual_labels, predictions)\n",
        "    print('Getting evaluations for multilabel problem')\n",
        "    print('Multilabel accuracy: ' + str(multi_label_accuracy(actual_labels, predictions)))\n",
        "    print('Multilabel precision: ' + str(multi_label_precision(actual_labels, predictions)))\n",
        "    print('Multilabel recall: ' + str(multi_label_recall(actual_labels, predictions)))\n",
        "    print(\"Percent of correctly decided label decisions: \" + str(100* (1-hamming_loss(actual_labels, predictions))))"
      ],
      "metadata": {
        "id": "oiKXimpCTQ9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for early stopping only after certain number of epochs. wait until delay epochs until early stopping\n",
        "#not same as patience. Want to not even start looking until delay is reached\n",
        "class DelayedEarlyStopping(EarlyStopping):\n",
        "    def __init__(self, monitor, min_delta=0, patience=0, verbose=0, mode='auto', delay = 100):\n",
        "        super(DelayedEarlyStopping, self).__init__(monitor=monitor, min_delta=min_delta, patience=patience,verbose=verbose, mode=mode)\n",
        "        self.delay = delay\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch > self.delay:\n",
        "            super().on_epoch_end(epoch, logs)"
      ],
      "metadata": {
        "id": "3HwiPVhqTXXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_output_to_predictions(res):\n",
        "    label_predictions = []\n",
        "    for i in range(res.shape[0]):\n",
        "        pred = [0]*53\n",
        "        for j in range(res.shape[1]):\n",
        "            if res[i][j] >= .5:\n",
        "                pred[j] = 1\n",
        "        label_predictions.append(pred)\n",
        "    return np.array(label_predictions)"
      ],
      "metadata": {
        "id": "zAqOPXAMTaKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Sequential()\n",
        "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)\n",
        "#e = Embedding(num_words_kept, word_vec_len, input_length=max_seq_len, trainable=True)\n",
        "model_cnn.add(e)\n",
        "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "model_cnn.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model_cnn.add(Dropout(.5))\n",
        "model_cnn.add(Dense(53, activation='sigmoid'))\n",
        "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
        "start = time.time()\n",
        "model_cnn.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
        "end = time.time()\n",
        "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ginxpp8oTcnO",
        "outputId": "53786435-f2eb-47bd-8d53-8ede57ac762b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "9/9 - 3s - loss: 0.6837 - raw_multi_label_accuracy: 0.0993 - val_loss: 0.4559 - val_raw_multi_label_accuracy: 0.1355 - 3s/epoch - 285ms/step\n",
            "Epoch 2/1000\n",
            "9/9 - 0s - loss: 0.4042 - raw_multi_label_accuracy: 0.1644 - val_loss: 0.2757 - val_raw_multi_label_accuracy: 0.1792 - 451ms/epoch - 50ms/step\n",
            "Epoch 3/1000\n",
            "9/9 - 0s - loss: 0.2995 - raw_multi_label_accuracy: 0.2245 - val_loss: 0.2493 - val_raw_multi_label_accuracy: 0.2823 - 431ms/epoch - 48ms/step\n",
            "Epoch 4/1000\n",
            "9/9 - 0s - loss: 0.2826 - raw_multi_label_accuracy: 0.2321 - val_loss: 0.2356 - val_raw_multi_label_accuracy: 0.2367 - 447ms/epoch - 50ms/step\n",
            "Epoch 5/1000\n",
            "9/9 - 0s - loss: 0.2613 - raw_multi_label_accuracy: 0.2397 - val_loss: 0.2257 - val_raw_multi_label_accuracy: 0.2708 - 452ms/epoch - 50ms/step\n",
            "Epoch 6/1000\n",
            "9/9 - 0s - loss: 0.2538 - raw_multi_label_accuracy: 0.2267 - val_loss: 0.2200 - val_raw_multi_label_accuracy: 0.2681 - 451ms/epoch - 50ms/step\n",
            "Epoch 7/1000\n",
            "9/9 - 0s - loss: 0.2427 - raw_multi_label_accuracy: 0.2322 - val_loss: 0.2154 - val_raw_multi_label_accuracy: 0.2542 - 449ms/epoch - 50ms/step\n",
            "Epoch 8/1000\n",
            "9/9 - 0s - loss: 0.2360 - raw_multi_label_accuracy: 0.2339 - val_loss: 0.2102 - val_raw_multi_label_accuracy: 0.2757 - 440ms/epoch - 49ms/step\n",
            "Epoch 9/1000\n",
            "9/9 - 0s - loss: 0.2291 - raw_multi_label_accuracy: 0.2401 - val_loss: 0.2059 - val_raw_multi_label_accuracy: 0.3086 - 453ms/epoch - 50ms/step\n",
            "Epoch 10/1000\n",
            "9/9 - 0s - loss: 0.2229 - raw_multi_label_accuracy: 0.2583 - val_loss: 0.2012 - val_raw_multi_label_accuracy: 0.2993 - 465ms/epoch - 52ms/step\n",
            "Epoch 11/1000\n",
            "9/9 - 0s - loss: 0.2178 - raw_multi_label_accuracy: 0.2549 - val_loss: 0.1982 - val_raw_multi_label_accuracy: 0.3081 - 449ms/epoch - 50ms/step\n",
            "Epoch 12/1000\n",
            "9/9 - 0s - loss: 0.2139 - raw_multi_label_accuracy: 0.2315 - val_loss: 0.1950 - val_raw_multi_label_accuracy: 0.2537 - 440ms/epoch - 49ms/step\n",
            "Epoch 13/1000\n",
            "9/9 - 0s - loss: 0.2108 - raw_multi_label_accuracy: 0.2623 - val_loss: 0.1916 - val_raw_multi_label_accuracy: 0.3142 - 438ms/epoch - 49ms/step\n",
            "Epoch 14/1000\n",
            "9/9 - 0s - loss: 0.2064 - raw_multi_label_accuracy: 0.2622 - val_loss: 0.1886 - val_raw_multi_label_accuracy: 0.3227 - 428ms/epoch - 48ms/step\n",
            "Epoch 15/1000\n",
            "9/9 - 0s - loss: 0.2034 - raw_multi_label_accuracy: 0.2540 - val_loss: 0.1856 - val_raw_multi_label_accuracy: 0.3296 - 452ms/epoch - 50ms/step\n",
            "Epoch 16/1000\n",
            "9/9 - 0s - loss: 0.1985 - raw_multi_label_accuracy: 0.2920 - val_loss: 0.1828 - val_raw_multi_label_accuracy: 0.3243 - 439ms/epoch - 49ms/step\n",
            "Epoch 17/1000\n",
            "9/9 - 0s - loss: 0.1959 - raw_multi_label_accuracy: 0.2812 - val_loss: 0.1798 - val_raw_multi_label_accuracy: 0.3048 - 441ms/epoch - 49ms/step\n",
            "Epoch 18/1000\n",
            "9/9 - 0s - loss: 0.1923 - raw_multi_label_accuracy: 0.2926 - val_loss: 0.1775 - val_raw_multi_label_accuracy: 0.3094 - 455ms/epoch - 51ms/step\n",
            "Epoch 19/1000\n",
            "9/9 - 0s - loss: 0.1897 - raw_multi_label_accuracy: 0.2981 - val_loss: 0.1750 - val_raw_multi_label_accuracy: 0.3032 - 443ms/epoch - 49ms/step\n",
            "Epoch 20/1000\n",
            "9/9 - 0s - loss: 0.1868 - raw_multi_label_accuracy: 0.2943 - val_loss: 0.1738 - val_raw_multi_label_accuracy: 0.3149 - 448ms/epoch - 50ms/step\n",
            "Epoch 21/1000\n",
            "9/9 - 0s - loss: 0.1840 - raw_multi_label_accuracy: 0.3198 - val_loss: 0.1717 - val_raw_multi_label_accuracy: 0.3050 - 455ms/epoch - 51ms/step\n",
            "Epoch 22/1000\n",
            "9/9 - 0s - loss: 0.1816 - raw_multi_label_accuracy: 0.3174 - val_loss: 0.1702 - val_raw_multi_label_accuracy: 0.3142 - 451ms/epoch - 50ms/step\n",
            "Epoch 23/1000\n",
            "9/9 - 0s - loss: 0.1796 - raw_multi_label_accuracy: 0.3360 - val_loss: 0.1686 - val_raw_multi_label_accuracy: 0.3189 - 447ms/epoch - 50ms/step\n",
            "Epoch 24/1000\n",
            "9/9 - 1s - loss: 0.1765 - raw_multi_label_accuracy: 0.3510 - val_loss: 0.1674 - val_raw_multi_label_accuracy: 0.3295 - 702ms/epoch - 78ms/step\n",
            "Epoch 25/1000\n",
            "9/9 - 1s - loss: 0.1745 - raw_multi_label_accuracy: 0.3468 - val_loss: 0.1671 - val_raw_multi_label_accuracy: 0.3288 - 866ms/epoch - 96ms/step\n",
            "Epoch 26/1000\n",
            "9/9 - 0s - loss: 0.1722 - raw_multi_label_accuracy: 0.3521 - val_loss: 0.1657 - val_raw_multi_label_accuracy: 0.3484 - 444ms/epoch - 49ms/step\n",
            "Epoch 27/1000\n",
            "9/9 - 0s - loss: 0.1703 - raw_multi_label_accuracy: 0.3818 - val_loss: 0.1648 - val_raw_multi_label_accuracy: 0.3304 - 466ms/epoch - 52ms/step\n",
            "Epoch 28/1000\n",
            "9/9 - 0s - loss: 0.1663 - raw_multi_label_accuracy: 0.3921 - val_loss: 0.1650 - val_raw_multi_label_accuracy: 0.3489 - 430ms/epoch - 48ms/step\n",
            "Epoch 29/1000\n",
            "9/9 - 0s - loss: 0.1645 - raw_multi_label_accuracy: 0.4011 - val_loss: 0.1629 - val_raw_multi_label_accuracy: 0.3288 - 442ms/epoch - 49ms/step\n",
            "Epoch 30/1000\n",
            "9/9 - 0s - loss: 0.1616 - raw_multi_label_accuracy: 0.4194 - val_loss: 0.1627 - val_raw_multi_label_accuracy: 0.3349 - 459ms/epoch - 51ms/step\n",
            "Epoch 31/1000\n",
            "9/9 - 0s - loss: 0.1600 - raw_multi_label_accuracy: 0.4222 - val_loss: 0.1624 - val_raw_multi_label_accuracy: 0.3433 - 439ms/epoch - 49ms/step\n",
            "Epoch 32/1000\n",
            "9/9 - 0s - loss: 0.1571 - raw_multi_label_accuracy: 0.4397 - val_loss: 0.1615 - val_raw_multi_label_accuracy: 0.3100 - 467ms/epoch - 52ms/step\n",
            "Epoch 33/1000\n",
            "9/9 - 0s - loss: 0.1544 - raw_multi_label_accuracy: 0.4456 - val_loss: 0.1617 - val_raw_multi_label_accuracy: 0.3128 - 439ms/epoch - 49ms/step\n",
            "Time to train with cross validation for early stopping: 17.909393072128296 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = nn_output_to_predictions(model_cnn.predict(x_test_seq))\n"
      ],
      "metadata": {
        "id": "pXbJT9L-TjCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_all_metrics(y_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "QtnJ2MCRT9K5",
        "outputId": "ce45699b-577d-408c-b7f7-3750e1f9add2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting evaluation metrics for each label:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e4a95610710b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_all_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-c6e39b004294>\u001b[0m in \u001b[0;36mget_all_metrics\u001b[0;34m(actual_labels, predictions)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting evaluation metrics for each label:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mget_per_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting evaluations for multilabel problem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Multilabel accuracy: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_label_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-7c1d5065d6c1>\u001b[0m in \u001b[0;36mget_per_label_metrics\u001b[0;34m(real_labels_matrix, predictions_labels_matrix)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_per_label_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_labels_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_labels_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenre_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenre_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mreal_labels_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_labels_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprediction_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_labels_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'genre_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = Input(shape=(max_seq_len,), dtype='int32')\n",
        "e = Embedding(num_words_kept, word_vec_len, weights=[embedding_matrix], input_length=max_seq_len, trainable=True)(model_input)\n",
        "two_word_filter = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(e)\n",
        "two_word_filter = GlobalMaxPooling1D()(two_word_filter)\n",
        "three_word_filter = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(e)\n",
        "three_word_filter = GlobalMaxPooling1D()(three_word_filter)\n",
        "four_word_filter = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(e)\n",
        "four_word_filter = GlobalMaxPooling1D()(four_word_filter)\n",
        "merged = concatenate([two_word_filter, three_word_filter, four_word_filter], axis=1)\n",
        "\n",
        "merged = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
        "merged = Dropout(0.5)(merged)\n",
        "merged = Dense(len(genre_dict))(merged)\n",
        "output = Activation('sigmoid')(merged)\n",
        "model = Model(inputs=[model_input], outputs=[output])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[raw_multi_label_accuracy])\n",
        "start = time.time()\n",
        "model.fit(x_train_seq, y_train, validation_split = .1, callbacks = [DelayedEarlyStopping(monitor = 'val_raw_multi_label_accuracy', patience = 5, delay=25)], epochs=1000, batch_size=100, verbose=2)\n",
        "end = time.time()\n",
        "print('Time to train with cross validation for early stopping: ' + str(end-start) + ' seconds')"
      ],
      "metadata": {
        "id": "IHR1i9WLUDJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}